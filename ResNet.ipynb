{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense,SimpleRNN, LSTM,Dropout,Convolution2D,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "NUM_INPUTS = 10\n",
    "SCALE_X = 1\n",
    "SCALE_Y = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random #random.shuffle() : shuffle the data of 1D\n",
    "from sklearn.utils import shuffle #for 2D shuffle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Dataset():\n",
    "  def __init__(self,num_classes = NUM_CLASSES,num_input = NUM_INPUTS,scale_x = SCALE_X, scale_y = SCALE_Y,\n",
    "               train_src=\"/content/gdrive/My Drive/YAMAKAWA_LAB/技術補佐員/動画/20230302/dataset/train.csv\",\n",
    "               test_src=\"/content/gdrive/My Drive/YAMAKAWA_LAB/技術補佐員/動画/20230302/dataset/test.csv\"\n",
    "               ):\n",
    "    self.train_src = train_src\n",
    "    self.test_src = test_src\n",
    "    self.num_classes = num_classes\n",
    "    self.num_input = num_input\n",
    "    self.scale_x = scale_x\n",
    "    self.scale_y = scale_y\n",
    "    #num of cpu\n",
    "    cpu_num = mp.cpu_count()\n",
    "    print(f\"{cpu_num} cpu is available\")\n",
    "\n",
    "    #return from self.function\n",
    "    self.url_train, self.label_train, self.url_test, self.label_test,self.width, self.height = self.load_dataset()\n",
    "    self.num_spatter_train = self.count_spatter(self.label_train)\n",
    "    self.num_spatter_test = self.count_spatter(self.label_test)\n",
    "    print(f\"-- Number of Spatter data --\\nTrain:{self.num_spatter_train}/{len(self.label_train)}\\nTest:{self.num_spatter_test}/{len(self.label_test)}\")\n",
    "\n",
    "    #primitive img data\n",
    "    \"\"\"\n",
    "    p = mp.Pool(cpu_num)\n",
    "    self.img_train = np.zeros((len(self.url_train),len(self.url_train[1]),self.width,self.height))\n",
    "    self.img_test = np.zeros((len(self.url_test),len(self.url_test[1]),self.width,self.height))\n",
    "    count_train = 0\n",
    "    count_test = 0\n",
    "    for img in tqdm(p.imap_unordered(self.url2img_step, self.url_train), total=self.url_train.shape[0]):\n",
    "      self.img_train[count_train] = img\n",
    "      count_train += 1\n",
    "    for img in tqdm(p.imap_unordered(self.url2img_step, self.img_test), total=self.url_test.shape[0]):\n",
    "      self.img_test[count_train] = img\n",
    "      count_test += 1\n",
    "    p.close()\n",
    "    \"\"\"\n",
    "    print(\"TRAIN PROCESSING ::: URL -> IMG\")\n",
    "    self.img_train_origin = self.url2img(self.url_train)\n",
    "    print(\"TEST PROCESSING ::: URL -> IMG\")\n",
    "    self.img_test_origin = self.url2img(self.url_test)\n",
    "\n",
    "    #process img data\n",
    "\n",
    "  def load_dataset(self):\n",
    "    \"\"\"load dataset from csv file\n",
    "    \"\"\"\n",
    "    train = pd.read_csv(filepath_or_buffer = self.train_src).values\n",
    "    test = pd.read_csv(filepath_or_buffer =self.test_src).values\n",
    "    #shuffle data\n",
    "    train = shuffle(train,random_state=42)#random_state = integer ; fix randomness with shuffling\n",
    "    test = shuffle(test,random_state=42)\n",
    "    #split data into urls and labels\n",
    "    url_train = train[:,1:]\n",
    "    label_train =  train[:,0]\n",
    "    url_test = test[:,1:]\n",
    "    label_test = test[:,0]\n",
    "\n",
    "    #show dataset\n",
    "    #img data\n",
    "    img=cv2.imread(train[200,1])\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    (width,height) = gray.shape\n",
    "    gray = np.resize(gray,(int(width*self.scale_x),int(height*self.scale_y)))\n",
    "    print(f\"dataset image shape : {gray.shape}\")\n",
    "    cv2.imshow(\"gray\",gray)\n",
    "\n",
    "    return url_train, label_train, url_test, label_test,width,height\n",
    "\n",
    "\n",
    "  def count_spatter(self,data):\n",
    "    \"\"\"count spatter data\n",
    "    Args :\n",
    "      data : label dataset\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for i in range(len(data)):\n",
    "      if data[i] == 1:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "  def url2img(self,data):\n",
    "    \"\"\"convert URL data to img data\n",
    "    \"\"\"\n",
    "    image_data = np.zeros((len(data),len(data[1]),int(self.width*self.scale_x),int(self.height*self.scale_y)))\n",
    "    print(f\"input image size :: {(int(self.width*self.scale_x),int(self.height*self.scale_y))}\")\n",
    "    size = (int(self.width*self.scale_x),int(self.height*self.scale_y))\n",
    "    for i in range(len(data)-1):\n",
    "      if i%100 == 99:\n",
    "          print(f\"{round((i+1)*100/len(data),0)}%\")\n",
    "      for j,name in enumerate(data[i]):\n",
    "        img=cv2.imread(name)\n",
    "        #print(img)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray  = cv2.resize(gray,size,interpolation = cv2.INTER_AREA)\n",
    "        image_data[i][-(j+1)]=gray #old to new\n",
    "    print(\"100% completed\")\n",
    "    return image_data\n",
    "\n",
    "  def url2img_step(self,data):\n",
    "    \"\"\"convert URL data to img data\n",
    "    \"\"\"\n",
    "    image_data = np.zeros((len(data),len(data[1]),int(self.width*self.scale_x),int(self.height*self.scale_y)))\n",
    "    print(f\"input image size :: {(int(self.width*self.scale_x),int(self.height*self.scale_y))}\")\n",
    "    for j,name in enumerate(data):\n",
    "      img=cv2.imread(name)\n",
    "      #print(img)\n",
    "      gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "      gray = np.resize(gray,(int(self.width*self.scale_x),int(self.height*self.scale_y)))\n",
    "      image_data[-(j+1)]=gray #old to new\n",
    "    return image_data\n",
    "\n",
    "  def processImg(self):\n",
    "    ## split data into training data and test data\n",
    "    image_train = self.img_train_origin.reshape(len(self.img_train_origin),self.num_input,int(self.width*self.scale_x),int(self.height*self.scale_y),1)\n",
    "    image_test = self.img_test_origin.reshape(len(self.img_test_origin),self.num_input,int(self.width*self.scale_x),int(self.height*self.scale_y),1)\n",
    "\n",
    "    #when calculating (dividing process) the type have to be float\n",
    "    image_train = image_train.astype(\"float32\")\n",
    "    image_test = image_test.astype(\"float32\")\n",
    "\n",
    "    #when training, it is convenient if the values are normalized\n",
    "    image_train= image_train/255\n",
    "    image_test = image_test/255\n",
    "\n",
    "    # converting data to float32, especially float32\n",
    "    image_train =np.asarray(image_train).astype(np.float32)\n",
    "    labels_train = np.asarray(self.label_train).astype(np.int32)\n",
    "    image_test =np.asarray(image_test).astype(np.float32)\n",
    "    labels_test = np.asarray(self.label_test).astype(np.int32)\n",
    "\n",
    "    label_train_onehot = self.label2vec(labels_train)\n",
    "    label_test_onehot = self.label2vec(labels_test)\n",
    "\n",
    "    return image_train,label_train_onehot, image_test,label_test_onehot\n",
    "\n",
    "  # convert label into array(2) [no-spatter, spatter]\n",
    "  def label2vec(self,label):\n",
    "    \"\"\"convert labels to one-hot vector\n",
    "    \"\"\"\n",
    "    count=0\n",
    "    lab = np.zeros((len(label),self.num_classes))\n",
    "    for i in range(len(label)):\n",
    "      if label[i] == 1: #spatter\n",
    "        lab[i,1] = 1\n",
    "        count+=1\n",
    "      else: #no spatter\n",
    "        lab[i,0] = 1\n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 cpu is available\n",
      "dataset image shape : (80, 80)\n",
      "-- Number of Spatter data --\n",
      "Train:1979/5179\n",
      "Test:271/591\n",
      "TRAIN PROCESSING ::: URL -> IMG\n",
      "input image size :: (80, 80)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0%\n",
      "4.0%\n",
      "6.0%\n",
      "8.0%\n",
      "10.0%\n",
      "12.0%\n",
      "14.0%\n",
      "15.0%\n",
      "17.0%\n",
      "19.0%\n",
      "21.0%\n",
      "23.0%\n",
      "25.0%\n",
      "27.0%\n",
      "29.0%\n",
      "31.0%\n",
      "33.0%\n",
      "35.0%\n",
      "37.0%\n",
      "39.0%\n",
      "41.0%\n",
      "42.0%\n",
      "44.0%\n",
      "46.0%\n",
      "48.0%\n",
      "50.0%\n",
      "52.0%\n",
      "54.0%\n",
      "56.0%\n",
      "58.0%\n",
      "60.0%\n",
      "62.0%\n",
      "64.0%\n",
      "66.0%\n",
      "68.0%\n",
      "70.0%\n",
      "71.0%\n",
      "73.0%\n",
      "75.0%\n",
      "77.0%\n",
      "79.0%\n",
      "81.0%\n",
      "83.0%\n",
      "85.0%\n",
      "87.0%\n",
      "89.0%\n",
      "91.0%\n",
      "93.0%\n",
      "95.0%\n",
      "97.0%\n",
      "98.0%\n",
      "100% completed\n",
      "TEST PROCESSING ::: URL -> IMG\n",
      "input image size :: (80, 80)\n",
      "17.0%\n",
      "34.0%\n",
      "51.0%\n",
      "68.0%\n",
      "85.0%\n",
      "100% completed\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(num_classes = 2,num_input = 10,scale_x = 1, scale_y = 1,\n",
    "                  train_src=r\"C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\csv\\resNet\\train.csv\",\n",
    "                  test_src=r\"C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\csv\\resNet\\test.csv\")\n",
    "img_train,label_train, img_test,label_test = dataset.processImg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2640812121731332518\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import L\n",
    "import tensorflow as tf\n",
    "from logging import Filter\n",
    "#from keras.engine.sequential import model_serialization\n",
    "#from tensorflow_datasets.core.dataset_builder import units\n",
    "from tensorflow import keras\n",
    "from keras import Input, Model\n",
    "from keras.layers import TimeDistributed, Activation,BatchNormalization,SeparableConv2D,GRU,Conv2D,GlobalAveragePooling2D,GlobalMaxPooling2D,LayerNormalization\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "#from keras.layers.core import Reshape\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D,AveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LayerNormalization\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import plot_model\n",
    "\n",
    "class ResNet():\n",
    "  def __init__(self,img_train,label_train,img_test,label_test,\n",
    "               num_filters,input_size,\n",
    "               kernel_size=3,lr = 0.1,num_classes=2,num_epoch = 100, batch = 32,threshold = 0.5,step_epoch=20,warmup = 20,\n",
    "               loss = \"binary_crossentropy\",classifier = \"lstm\",checkpoint = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\ML_results\\resnet\\model\\spatter_resnet.keras',\n",
    "               tpu=False,cosine_scheduler = True):\n",
    "    self.img_train = img_train\n",
    "    self.label_train = label_train\n",
    "    self.img_test = img_test\n",
    "    self.label_test = label_test\n",
    "    self.kernel = (kernel_size,kernel_size)\n",
    "    self.num_filters = num_filters\n",
    "    self.input_size = input_size\n",
    "    self.lr = lr\n",
    "    self.warmup = warmup\n",
    "    self.loss = loss\n",
    "    self.classifier = classifier\n",
    "    self.num_classes = num_classes\n",
    "    self.step_epoch = step_epoch\n",
    "    self.epochs = num_epoch\n",
    "\n",
    "    self.feature_size =  [80**2,40**2,20**2,10**2,5**2,3**2,2**2,1]\n",
    "\n",
    "    #model construction\n",
    "    if tpu:\n",
    "      print(\" -- MODE :: TPU -- \")\n",
    "      strategy = tf.distribute.TPUStrategy(tpu)\n",
    "      print(\"Number of replicas: {strategy.num_replicas_in_sync}\")\n",
    "      with strategy.scope():\n",
    "          self.model = self.build_model()\n",
    "    else:\n",
    "      print(\" -- MODE :: CPU -- \")\n",
    "      self.model = self.build_model()\n",
    "\n",
    "    #Model summary\n",
    "    self.model.summary()\n",
    "    plot_model(self.model,show_shapes = True,show_layer_names = False)\n",
    "\n",
    "    #call back\n",
    "    if cosine_scheduler:\n",
    "      callback = tf.keras.callbacks.LearningRateScheduler(self.cosine_scheduler)\n",
    "    if not cosine_scheduler:\n",
    "      callback = tf.keras.callbacks.LearningRateScheduler(self.scheduler)\n",
    "    Modelcheckpoint = keras.callbacks.ModelCheckpoint(filepath = checkpoint, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    #model training\n",
    "    self.history = self.model.fit(img_train, label_train, epochs=num_epoch,validation_data = (img_test,label_test), batch_size = batch)\n",
    "                    #,callbacks = [callback,Modelcheckpoint])\n",
    "    #plot learning status\n",
    "    self.plotData()\n",
    "\n",
    "    #evaluation\n",
    "    self.threshold = threshold\n",
    "    self.metricsPlot(test=False)\n",
    "    self.metricsPlot(test=True)\n",
    "\n",
    "  def res_conv_block(self,input,num_filter,pooling=False):\n",
    "    \"\"\"residual convolutional layer\n",
    "    \"\"\"\n",
    "    residual = input\n",
    "    conv2d_1 = Conv2D(num_filter,self.kernel,padding = \"same\")\n",
    "    outputs = TimeDistributed(conv2d_1)(input)\n",
    "    #conv2d_2 = Conv2D(num_filter,self.kernel,padding = \"same\")\n",
    "    #outputs = TimeDistributed(conv2d_2)(outputs)\n",
    "\n",
    "    if pooling:#whether Maxpooling layer is or not\n",
    "      pool_0 = MaxPooling2D((2,2),strides = 2,padding='same')#32*32\n",
    "      outputs = TimeDistributed(pool_0)(outputs)\n",
    "      conv_res = Conv2D(num_filter,1,strides = 2)\n",
    "      residual = TimeDistributed(conv_res)(residual)\n",
    "    else:\n",
    "      conv_res = Conv2D(num_filter,1)\n",
    "      residual = TimeDistributed(conv_res)(residual)\n",
    "\n",
    "    outputs = layers.add([outputs,residual])\n",
    "    filter = Activation(\"relu\")\n",
    "    outputs = TimeDistributed(filter)(outputs)\n",
    "    return outputs\n",
    "\n",
    "  def build_model(self):\n",
    "    \"\"\"build model structure\n",
    "    classifier : type of classifier ex) 'lstm','dense','bilstm'\n",
    "    num_filters(list) : num of filters ex) [4,8,16,32] ---\n",
    "    \"\"\"\n",
    "    #conv part\n",
    "    input = Input(shape=self.input_size)\n",
    "    conv = self.res_conv_block(input,self.num_filters[0],pooling=True)\n",
    "    for i in range(1,len(self.num_filters)-1):\n",
    "      conv = self.res_conv_block(conv,self.num_filters[i],pooling=True)\n",
    "    conv2d = Conv2D(self.num_filters[-1],self.kernel,padding = \"same\")\n",
    "    outputs = TimeDistributed(conv2d)(conv)\n",
    "    filter = Activation('relu')\n",
    "    outputs = TimeDistributed(filter)(outputs)\n",
    "    pool = MaxPooling2D((2,2),strides = 2,padding='same')#32*32\n",
    "    outputs = TimeDistributed(pool)(outputs)\n",
    "\n",
    "    #classifier part\n",
    "    if self.classifier.lower() == \"lstm\":\n",
    "      x = TimeDistributed(Flatten())(outputs)\n",
    "      x = LSTM(self.num_filters[-1]*self.feature_size[len(self.num_filters)])(x)\n",
    "      x = Dropout(0.1)(x)\n",
    "      x = Dense(self.num_filters[-1]*self.feature_size[len(self.num_filters)])(x)\n",
    "    elif self.classifier.lower() == 'dense':\n",
    "      outputs = Flatten()(outputs)\n",
    "      x = Dense(self.num_filters[-1]*self.feature_size[len(self.num_filters)]*10)(outputs)\n",
    "      x = Activation('relu')(x)\n",
    "      x =Dropout(0.1)(x)\n",
    "\n",
    "      x = Dense(self.num_filters[-1]*self.feature_size[len(self.num_filters)]*10//2)(outputs)\n",
    "      x = Activation('relu')(x)\n",
    "      x = Dropout(0.1)(x)\n",
    "\n",
    "      x = Dense(self.num_filters[-1]*self.feature_size[len(self.num_filters)]*10//4)(outputs)\n",
    "      x = Activation('relu')(x)\n",
    "      x = Dropout(0.1)(x)\n",
    "    elif self.classifier.lower() == 'bilstm':\n",
    "      x = TimeDistributed(Flatten())(outputs)\n",
    "      x = Bidirectional(LSTM(self.num_filters[-1]*self.feature_size[len(self.num_filters)]//2))(x)\n",
    "      x = Dropout(0.1)(x)\n",
    "      x = Dense(self.num_filters[-1]*self.feature_size[len(self.num_filters)])(x)\n",
    "\n",
    "    #output layer\n",
    "    output = Dense(self.num_classes,activation='softmax')(x)\n",
    "\n",
    "    #define model\n",
    "    model = Model(inputs = input,outputs = output)\n",
    "\n",
    "    # Compiling\n",
    "    #opt = keras.optimizers.RMSprop(learning_rate = self.lr)\n",
    "    opt = keras.optimizers.Adam(learning_rate = self.lr)\n",
    "    model.compile(optimizer = opt,\n",
    "                  loss=self.loss,\n",
    "                  metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "  def scheduler(self,epoch,lr):\n",
    "    if (epoch+1)%self.step_epoch == 0:\n",
    "      lr = lr*0.1\n",
    "    return lr\n",
    "\n",
    "  def cosine_scheduler(self, epoch,lr):\n",
    "      \"\"\"\n",
    "      Arguments\n",
    "      ---------\n",
    "      epoch : int\n",
    "          現在のエポック数．\n",
    "      \"\"\"\n",
    "      progress = (epoch -self.warmup) / (self.epochs - self.warmup)\n",
    "      progress = np.clip(progress, 0.0, 1.0)\n",
    "      lr = self.lr * 0.5 * (1. + np.cos(np.pi * progress))\n",
    "\n",
    "      if self.warmup:\n",
    "          lr = lr * min(1., (epoch+1) / self.warmup)\n",
    "\n",
    "      return lr\n",
    "\n",
    "  def plotData(self):\n",
    "    #plot vonverging process :\n",
    "    plt.subplots(figsize = (10,5))\n",
    "    plt.plot(self.history.history[\"loss\"],label = \"Loss\")\n",
    "    plt.plot(self.history.history[\"val_loss\"], label = \"val_loss\")\n",
    "    plt.title(\"Converging state\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"binary_crossentropy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplots(figsize = (10,5))\n",
    "    plt.plot(self.history.history['accuracy'], label = \"accuracy\")\n",
    "    plt.plot(self.history.history['val_accuracy'],label = 'val_accuracy')\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')  # Y軸ラベル\n",
    "    plt.xlabel('epoch')  # X軸ラベル\n",
    "    plt.grid()\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "  threshold = 0.5\n",
    "\n",
    "  #split label data into a scaler\n",
    "  def vec2scaler(self,data):\n",
    "    spatter_label = []\n",
    "    non_label = []\n",
    "    for i in range(data.shape[0]):\n",
    "      if data[i][0] == 1: #non spatter\n",
    "        non_label.append(1)\n",
    "        spatter_label.append(None)\n",
    "      else:#spatter\n",
    "        non_label.append(None)\n",
    "        spatter_label.append(1)\n",
    "    return spatter_label,non_label\n",
    "\n",
    "  def metrics_change(self,predict_data,label_data):\n",
    "    Spatter = []\n",
    "\n",
    "    #decide spatter or not according to threshold\n",
    "    for i in range(predict_data.shape[0]):\n",
    "      if predict_data[i,1] >= self.threshold:\n",
    "        Spatter.append(1)\n",
    "      else :\n",
    "        Spatter.append(0)\n",
    "\n",
    "      spatter_label,non_label = self.vec2scaler(label_data)\n",
    "\n",
    "    #evaluation parameter\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(spatter_label)):\n",
    "\n",
    "      if spatter_label[i] == 1:\n",
    "        if Spatter[i] == 1:#TP\n",
    "          TP +=1\n",
    "        elif Spatter[i] == 0: #FN\n",
    "          FN +=1\n",
    "      elif non_label[i] == 1:\n",
    "        if Spatter[i] == 1:#FP\n",
    "          FP += 1\n",
    "        elif Spatter[i] == 1:#TN\n",
    "          TN += 1\n",
    "\n",
    "    print(\"(TP,FN,FP,TN)\",(TP,FN,FP,TN))\n",
    "\n",
    "    all = len(spatter_label)\n",
    "    print(all)\n",
    "    accuracy = (TP+TN)/all\n",
    "    if TP+FP > 0:\n",
    "      precision = TP/(TP+FP)\n",
    "    else:\n",
    "      precision = None\n",
    "    recall = TP/(TP+FN)\n",
    "    if precision == 0 or precision == None or recall == 0:\n",
    "      f_value = None\n",
    "    else:\n",
    "      f_value = 2/(1/precision+1/recall)\n",
    "\n",
    "    return accuracy, precision, recall,f_value\n",
    "\n",
    "  def frange(self,start, end , step):\n",
    "    if step == 0:\n",
    "        raise ValueError('step must not be zero')\n",
    "\n",
    "    start = float(start)\n",
    "    end = float(end)\n",
    "    step = float(step)\n",
    "\n",
    "    # range関数と同様な振る舞いにする\n",
    "    if abs(step) > abs(start - end):\n",
    "        return [start]\n",
    "    if step > 0 and end - start < 0:\n",
    "        return []\n",
    "    elif step < 0 and end - start > 0:\n",
    "        return []\n",
    "\n",
    "    exp = len(str(step).split('.')[1])  # 丸める際に使用する桁数\n",
    "    result = [start]\n",
    "    val = start\n",
    "    if step > 0:\n",
    "        while (val := round(val + step, exp)) < end:\n",
    "            result.append(val)\n",
    "    else:\n",
    "        while (val := round(val + step, exp)) > end:\n",
    "            result.append(val)\n",
    "    return result\n",
    "\n",
    "  def metricsPlot(self,test=True):\n",
    "    Accuracy = []\n",
    "    Precision = []\n",
    "    Recall = []\n",
    "    F_value = []\n",
    "    Threshold = []\n",
    "\n",
    "    if test:\n",
    "      print(\"TEST DATA EVALUATION\")\n",
    "      predict_data =self. model.predict(self.img_test)\n",
    "    else:\n",
    "      print(\"TRAIN DATA EVALUATION\")\n",
    "      predict_data = self.model.predict(self.img_train)\n",
    "    for threshold in self.frange(0.0,1.0,0.05):\n",
    "      if test:\n",
    "        accuracy,precision,recall,f_value = self.metrics_change(predict_data,self.label_test)\n",
    "      else:\n",
    "        accuracy,precision,recall,f_value = self.metrics_change(predict_data,self.label_train)\n",
    "      Threshold.append(threshold)\n",
    "      Accuracy.append(accuracy)\n",
    "      Precision.append(precision)\n",
    "      Recall.append(recall)\n",
    "      F_value.append(f_value)\n",
    "\n",
    "    plt.subplots(figsize=(7,7))\n",
    "    plt.plot(Threshold,Accuracy,color ='b',label = 'Accuracy')\n",
    "    plt.plot(Threshold,Precision,color ='y',label = 'Precision')\n",
    "    plt.plot(Threshold,Recall,color ='g',label = 'Recall')\n",
    "    plt.plot(Threshold,F_value,linewidth = 3,color ='r',label = 'F value')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- MODE :: CPU -- \n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 10, 80, 80, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " time_distributed_12 (TimeD  (None, 10, 80, 80, 2)        20        ['input_2[0][0]']             \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_13 (TimeD  (None, 10, 40, 40, 2)        0         ['time_distributed_12[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_14 (TimeD  (None, 10, 40, 40, 2)        4         ['input_2[0][0]']             \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 10, 40, 40, 2)        0         ['time_distributed_13[0][0]', \n",
      "                                                                     'time_distributed_14[0][0]'] \n",
      "                                                                                                  \n",
      " time_distributed_15 (TimeD  (None, 10, 40, 40, 2)        0         ['add_2[0][0]']               \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_16 (TimeD  (None, 10, 40, 40, 4)        76        ['time_distributed_15[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_17 (TimeD  (None, 10, 20, 20, 4)        0         ['time_distributed_16[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_18 (TimeD  (None, 10, 20, 20, 4)        12        ['time_distributed_15[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 10, 20, 20, 4)        0         ['time_distributed_17[0][0]', \n",
      "                                                                     'time_distributed_18[0][0]'] \n",
      "                                                                                                  \n",
      " time_distributed_19 (TimeD  (None, 10, 20, 20, 4)        0         ['add_3[0][0]']               \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_20 (TimeD  (None, 10, 20, 20, 8)        296       ['time_distributed_19[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_21 (TimeD  (None, 10, 20, 20, 8)        0         ['time_distributed_20[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_22 (TimeD  (None, 10, 10, 10, 8)        0         ['time_distributed_21[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_23 (TimeD  (None, 10, 800)              0         ['time_distributed_22[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 800)                  5123200   ['time_distributed_23[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 800)                  0         ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 800)                  640800    ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 2)                    1602      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5766010 (22.00 MB)\n",
      "Trainable params: 5766010 (22.00 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Epoch 1/200\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "BATCH = 64\n",
    "HEIGHT = int(SCALE_X * dataset.width)\n",
    "WIDTH = int(SCALE_Y * dataset.height)\n",
    "THRESHOLD = 0.5\n",
    "KERNEL_SIZE = 3\n",
    "LEARNING_RATE = 0.1\n",
    "STEP_EPOCH = 15\n",
    "WARMUP = 20\n",
    "FILTERS_CONV = [2,4,8]\n",
    "LOSS = \"binary_crossentropy\"\n",
    "CLASSIFIER = \"lstm\"\n",
    "CHECKPOINT = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\ML_results\\resnet\\model\\spatter_resnet_0727.keras'\n",
    "\n",
    "resnet = ResNet(img_train=img_train,label_train=label_train,img_test=img_test,label_test=label_test,\n",
    "               num_filters=FILTERS_CONV,input_size=(NUM_INPUTS,WIDTH,HEIGHT,1),\n",
    "               kernel_size=KERNEL_SIZE,lr = LEARNING_RATE,num_classes=NUM_CLASSES,num_epoch = EPOCHS, batch = BATCH,threshold = THRESHOLD,step_epoch = STEP_EPOCH,warmup = WARMUP,\n",
    "               loss = LOSS,classifier = CLASSIFIER,checkpoint = CHECKPOINT,\n",
    "               tpu=False,cosine_scheduler=True)\n",
    "model = resnet.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#visualize model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model,show_shapes = True,show_layer_names = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#make heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_name = 'time_distributed_274'\n",
    "classifier_layer_names = ['time_distributed_275','time_distributed_276','lstm_7','dropout_7','dense_14','dense_15']\n",
    "last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "last_conv_layer_model = keras.Model(model.inputs,last_conv_layer.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adapt classifer for last conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_input = keras.Input(shape = last_conv_layer.output.shape[1:])\n",
    "x = classifier_input\n",
    "#make model\n",
    "for layer_name in classifier_layer_names:\n",
    "  x = model.get_layer(layer_name)(x)\n",
    "classifier_model = keras.Model(classifier_input,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get gradients of highly predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "img = img_train[2]\n",
    "img = np.expand_dims(img,axis=0)\n",
    "with tf.GradientTape() as tape:\n",
    "\n",
    "  #calculate last conv layer's activation and enroll for GradientTape\n",
    "  last_conv_layer_output = last_conv_layer_model(img) #(1,9,7.7,32)\n",
    "  print(last_conv_layer_output.shape)\n",
    "  tape.watch(last_conv_layer_output)\n",
    "\n",
    "  #get a channel of most highly predicted class\n",
    "  preds = classifier_model(last_conv_layer_output)\n",
    "  top_pred_index = tf.argmax(preds[0])\n",
    "  top_class_channel = preds[:,top_pred_index] #tensor shape=(1,)\n",
    "\n",
    "#last class gradient based on last conv layer as input\n",
    "grads = tape.gradient(top_class_channel,last_conv_layer_output) #(1,9,7,7,32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weighting each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heatmap = np.zeros((last_conv_layer_output.shape[1],last_conv_layer_output.shape[2],last_conv_layer_output.shape[3]))\n",
    "for i in range(grads.shape[1]):\n",
    "  grads_tmp = grads[0,i,:,:,:]\n",
    "  #averaging for each filter\n",
    "  pooled_grads = tf.reduce_mean(grads_tmp,axis=(0,1)).numpy()\n",
    "  print(pooled_grads.shape)#(1,9)\n",
    "  last_conv_layer_output_tmp = last_conv_layer_output.numpy()[0][i]\n",
    "  print(last_conv_layer_output_tmp.shape)#\n",
    "\n",
    "  #multiply weights by each filter\n",
    "  for j in range(pooled_grads.shape[-1]):\n",
    "    last_conv_layer_output_tmp[:,:,j] *= pooled_grads[j]\n",
    "\n",
    "  #average for each filter\n",
    "  heatmap = np.mean(last_conv_layer_output_tmp,axis = -1) #all\n",
    "  print(heatmap.shape)\n",
    "  Heatmap[i,:,:] = heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalization of heatmap for 0~1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  Heatmap[i,:,:] = np.maximum(Heatmap[i,:,:],0)\n",
    "  Heatmap[i,:,:] = Heatmap[i,:,:]/np.max(Heatmap[i,:,:])\n",
    "  plt.matshow(Heatmap[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "superimpose heatmap to original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "for i in range(10):\n",
    "  img = img_train[2][i]\n",
    "  img = keras.utils.img_to_array(img)\n",
    "\n",
    "  heatmap = Heatmap[i,:,:]\n",
    "  heatmap = np.uint8(255*heatmap)\n",
    "  #coloring heatmap\n",
    "  jet = cm.get_cmap('jet')\n",
    "  jet_colors = jet(np.arange(256))[:,:3]\n",
    "  jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "  #make img with heatmap\n",
    "  jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "  jet_heatmap = jet_heatmap.resize((img.shape[1],img.shape[0])) #order is different betweendimage and array\n",
    "  jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "  #transparency rate = 40%\n",
    "  superimposed_img = jet_heatmap*0.1+img\n",
    "  superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "  plt.figure(figsize=(30,3))\n",
    "  plt.subplot(1,10,i+1)\n",
    "  plt.imshow(superimposed_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "furukawa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
