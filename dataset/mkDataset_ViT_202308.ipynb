{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## single frame analysis: whether there are large spatta?\n",
    "import cv2\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from numpy import dtype,uint8\n",
    "import scipy.ndimage as ndimage\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check number of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20220401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,1):: 540\n",
      "(1,2):: 537\n",
      "(2,1):: 1080\n",
      "(2,2):: 1079\n",
      "(3,1):: 2162\n",
      "(3,2):: 2162\n",
      "(4,1):: 540\n",
      "(4,2):: 540\n",
      "(5,1):: 1080\n",
      "(5,2):: 1081\n",
      "(6,1):: 2163\n",
      "(6,2):: 2162\n",
      "(7,1):: 540\n",
      "(7,2):: 540\n",
      "(8,1):: 1082\n",
      "(8,2):: 1079\n",
      "(9,1):: 2161\n",
      "(9,2):: 2162\n",
      "(10,1):: 540\n",
      "(10,2):: 540\n",
      "(11,1):: 1080\n",
      "(11,2):: 1080\n",
      "(12,1):: 2161\n",
      "(12,2):: 2092\n"
     ]
    }
   ],
   "source": [
    "dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401'\n",
    "def checkNum(dir=dir,date_20221020=False):\n",
    "    for i in range(1,13):\n",
    "        for j in range(1,3):\n",
    "            if date_20221020 :\n",
    "                src_img_dir = os.path.join(dir,\"{}\\crop\".format((i-1)*2+j+20))\n",
    "            else:\n",
    "                #get num of file in a directory\n",
    "                src_img_dir = os.path.join(dir,\"{}_{}\\crop\".format(i,j))\n",
    "\n",
    "            num_photo = sum(os.path.isfile(os.path.join(src_img_dir,name)) for name in os.listdir(src_img_dir))\n",
    "\n",
    "            print(f\"({i},{j})::\",num_photo)\n",
    "\n",
    "checkNum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20220603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,1):: 540\n",
      "(1,2):: 533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,1):: 1079\n",
      "(2,2):: 1080\n",
      "(3,1):: 2162\n",
      "(3,2):: 2163\n",
      "(4,1):: 457\n",
      "(4,2):: 540\n",
      "(5,1):: 1079\n",
      "(5,2):: 1080\n",
      "(6,1):: 2162\n",
      "(6,2):: 2162\n",
      "(7,1):: 541\n",
      "(7,2):: 540\n",
      "(8,1):: 1080\n",
      "(8,2):: 1080\n",
      "(9,1):: 2162\n",
      "(9,2):: 2163\n",
      "(10,1):: 539\n",
      "(10,2):: 539\n",
      "(11,1):: 1080\n",
      "(11,2):: 1079\n",
      "(12,1):: 2162\n",
      "(12,2):: 2162\n"
     ]
    }
   ],
   "source": [
    "DIR_20220603 = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220603'\n",
    "checkNum(dir = DIR_20220603)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#20221020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,1):: 244\n",
      "(1,2):: 448\n",
      "(2,1):: 895\n",
      "(2,2):: 245\n",
      "(3,1):: 448\n",
      "(3,2):: 863\n",
      "(4,1):: 235\n",
      "(4,2):: 430\n",
      "(5,1):: 857\n",
      "(5,2):: 233\n",
      "(6,1):: 312\n",
      "(6,2):: 880\n",
      "(7,1):: 236\n",
      "(7,2):: 434\n",
      "(8,1):: 866\n",
      "(8,2):: 240\n",
      "(9,1):: 440\n",
      "(9,2):: 883\n",
      "(10,1):: 240\n",
      "(10,2):: 442\n",
      "(11,1):: 889\n",
      "(11,2):: 242\n",
      "(12,1):: 447\n",
      "(12,2):: 892\n"
     ]
    }
   ],
   "source": [
    "DIR_20221020 = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20221020'\n",
    "checkNum(dir = DIR_20221020,date_20221020=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#concatenate imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatImg(x_patch = 3, y_patch = 3,INVERSE = True):\n",
    "    h,w,c = 80,80,1\n",
    "    H = h*3\n",
    "    W = w*3\n",
    "    concat = np.zeros((H,W,c))\n",
    "    folder_path = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401\\1_1\\crop'\n",
    "    for i in range(9):\n",
    "        file = \"{:04d}.jpg\".format(i+10)\n",
    "        path = os.path.join(folder_path,file)\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        img = np.expand_dims(np.array(img).astype(\"int32\"),2)\n",
    "        #new to old\n",
    "        if INVERSE:\n",
    "            row =  (x_patch-1) - i//3\n",
    "            column = (y_patch-1) - i%3\n",
    "            concat[h*row:h*(row+1),w*column:w*(column+1),:] = img\n",
    "        #old to new\n",
    "        else:\n",
    "            row = i//3\n",
    "            column = i%3\n",
    "            concat[h*row:h*(row+1),w*column:w*(column+1),:] = img\n",
    "    cv2.imwrite(r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401\\concat_inverse.jpg',concat)\n",
    "\n",
    "concatImg(INVERSE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "class Dataset():\n",
    "  def __init__(self,start_index=13,x_patch = 3, y_patch = 3, height = 80,width = 80,speed=100,\n",
    "                date = \"20220401\",\n",
    "                src_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20220401',\n",
    "                dir_concatImg = \"concat_vit\"\n",
    "              ):\n",
    "    self.start_index=start_index\n",
    "    #num of patches\n",
    "    self.x_patch = x_patch\n",
    "    self.y_patch = y_patch  \n",
    "    #size for 1 patch\n",
    "    self.height = height\n",
    "    self.width = width\n",
    "    #size for concatenated img\n",
    "    self.H = x_patch*height\n",
    "    self.W = y_patch*width\n",
    "    #date of dataset\n",
    "    self.date = date\n",
    "    #img src directory\n",
    "    self.src_dir = src_dir\n",
    "    #directory for concat img\n",
    "    self.dir_concatImg = dir_concatImg\n",
    "    self.speed = speed\n",
    "    #load spatter labels from .txt file\n",
    "    #load spatter labels from .txt fil   \n",
    "    if speed==100:\n",
    "        dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, {speed}mm_s\\video'.format(speed=speed)\n",
    "        self.spatter_data_13 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(13)), dtype='int').tolist()\n",
    "        self.spatter_data_14 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(14)), dtype='int').tolist()\n",
    "        self.spatter_data_15 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(15)), dtype='int').tolist()\n",
    "        self.spatter_data_16 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(16)), dtype='int').tolist()\n",
    "        #self.spatter_data_17 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(17)), dtype='int').tolist()\n",
    "        self.spatter_data_18 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(18)), dtype='int').tolist()\n",
    "        self.spatter_data_19 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(19)), dtype='int').tolist()\n",
    "        self.spatter_data_20 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(20)), dtype='int').tolist()\n",
    "        self.spatter_data_21 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(21)), dtype='int').tolist()\n",
    "        self.spatter_data_22 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(22)), dtype='int').tolist()\n",
    "        self.spatter_data_23 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(23)), dtype='int').tolist()\n",
    "        self.spatter_data_24 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(24)), dtype='int').tolist()\n",
    "        self.spatter_data_25 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(25)), dtype='int').tolist()\n",
    "        self.spatter_data_26 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(26)), dtype='int').tolist()\n",
    "        self.spatter_data_27 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(27)), dtype='int').tolist()\n",
    "        self.spatter_data_28 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(28)), dtype='int').tolist()\n",
    "        self.spatter_data_29 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(29)), dtype='int').tolist()\n",
    "        self.spatter_data_30 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(30)), dtype='int').tolist()\n",
    "        self.spatter_data_31 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(31)), dtype='int').tolist()\n",
    "        self.spatter_data_32 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(32)), dtype='int').tolist()\n",
    "        self.spatter_data_33 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(33)), dtype='int').tolist()\n",
    "        self.spatter_data_34 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(34)), dtype='int').tolist()\n",
    "        self.spatter_data_35 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(35)), dtype='int').tolist()\n",
    "        self.spatter_data_36 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(36)), dtype='int').tolist()\n",
    "        self.spatter_data_37 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(37)), dtype='int').tolist()\n",
    "        self.spatter_data_38 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(38)), dtype='int').tolist()\n",
    "        self.spatter_data_39 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(39)), dtype='int').tolist()\n",
    "        self.spatter_data_40 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(40)), dtype='int').tolist()\n",
    "        self.spatter_data_41 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(41)), dtype='int').tolist()\n",
    "        self.spatter_data_42 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(42)), dtype='int').tolist()\n",
    "    elif speed==200:\n",
    "      dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, {speed}mm_s\\video'.format(speed=speed)\n",
    "      self.spatter_data_51 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(51)), dtype='int').tolist()\n",
    "      self.spatter_data_52 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(52)), dtype='int').tolist()\n",
    "      self.spatter_data_53 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(53)), dtype='int').tolist()\n",
    "      self.spatter_data_54 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(54)), dtype='int').tolist()\n",
    "      self.spatter_data_55 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(55)), dtype='int').tolist()\n",
    "      self.spatter_data_56 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(56)), dtype='int').tolist()\n",
    "      self.spatter_data_57 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(57)), dtype='int').tolist()\n",
    "      self.spatter_data_58 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(58)), dtype='int').tolist()\n",
    "      self.spatter_data_59 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(59)), dtype='int').tolist()\n",
    "      self.spatter_data_60 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(60)), dtype='int').tolist()\n",
    "      self.spatter_data_61 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(61)), dtype='int').tolist()\n",
    "      self.spatter_data_62 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(62)), dtype='int').tolist()\n",
    "      self.spatter_data_63 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(63)), dtype='int').tolist()\n",
    "      self.spatter_data_64 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(64)), dtype='int').tolist()\n",
    "      self.spatter_data_65 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(65)), dtype='int').tolist()\n",
    "      self.spatter_data_66 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(66)), dtype='int').tolist()\n",
    "      self.spatter_data_67 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(67)), dtype='int').tolist()\n",
    "      self.spatter_data_68 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(68)), dtype='int').tolist()\n",
    "      self.spatter_data_69 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(69)), dtype='int').tolist()\n",
    "      self.spatter_data_70 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(70)), dtype='int').tolist()\n",
    "      self.spatter_data_71 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(71)), dtype='int').tolist()\n",
    "      self.spatter_data_72 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(72)), dtype='int').tolist()\n",
    "      self.spatter_data_73 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(73)), dtype='int').tolist()\n",
    "      self.spatter_data_74 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(74)), dtype='int').tolist()\n",
    "      self.spatter_data_75 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(75)), dtype='int').tolist()\n",
    "      self.spatter_data_76 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(76)), dtype='int').tolist()\n",
    "      self.spatter_data_77 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(77)), dtype='int').tolist()\n",
    "      self.spatter_data_78 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(78)), dtype='int').tolist()\n",
    "      self.spatter_data_79 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(79)), dtype='int').tolist()\n",
    "      self.spatter_data_80 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(80)), dtype='int').tolist()\n",
    "\n",
    "\n",
    "  def concatImg(self,index,src_img_dir,save_dir,INVERSE = False):\n",
    "      \"\"\"concatenate images\n",
    "      Args:\n",
    "        index: index for spatter frame, so index is the latest index in 9 frames, ie. index, index-1,index-2,..., index-8\n",
    "        src_img_dir : source directory of cropped imgs\n",
    "        save_dir : save dir for concatenate images\n",
    "        x_patch, y_patch : number of patches in x and y axis\n",
    "        INVERSE : patch order. If INVERSE is True, new to old is applied\n",
    "      Return:\n",
    "        file_path : path for concat img\n",
    "        write concatenated images into designated directory\n",
    "      \"\"\"\n",
    "      concat = np.zeros((self.H,self.W,1))\n",
    "      for i in range(9):\n",
    "          file = \"{:03d}.jpg\".format(index-i) #from new to old\n",
    "          path = os.path.join(src_img_dir,file)\n",
    "          img = cv2.imread(path)\n",
    "          img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #gray scale\n",
    "          img = np.expand_dims(np.array(img).astype(\"int32\"),2) #add color channel : (height,width,1)\n",
    "          #new to old\n",
    "          if INVERSE:\n",
    "              row = i//3\n",
    "              column = i%3\n",
    "              concat[self.height*row:self.height*(row+1),self.width*column:self.width*(column+1),:] = img\n",
    "          #old to new\n",
    "          else:\n",
    "              row =  (self.x_patch-1) - i//3\n",
    "              column = (self.y_patch-1) - i%3\n",
    "              concat[self.height*row:self.height*(row+1),self.width*column:self.width*(column+1),:] = img\n",
    "      file_path = os.path.join(save_dir,f\"{index:03d}.jpg\")\n",
    "      cv2.imwrite(file_path,concat)\n",
    "      return file_path\n",
    "\n",
    "  def checkImg(self,file_path):\n",
    "    \"\"\"check whether laser process has started\n",
    "\n",
    "    Args:\n",
    "        file_path (str): img file path\n",
    "    \"\"\"\n",
    "    img = cv2.imread(file_path)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    gray = gray\n",
    "    ret,thresh = cv2.threshold(gray,60,255,cv2.THRESH_BINARY)\n",
    "    #find contours\n",
    "    contours, hierarchy = cv2.findContours(np.array(thresh,dtype=uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    Area = []\n",
    "    #detect laser area\n",
    "    if (bool(contours)==True):\n",
    "      #面積(px*px)\n",
    "      for j in contours:\n",
    "        area = cv2.contourArea(j)\n",
    "        Area.append(area)\n",
    "\n",
    "      if Area:\n",
    "        area_max = np.max(Area)\n",
    "        if area_max > 64:\n",
    "           ret = True\n",
    "           return ret\n",
    "        else:\n",
    "           ret = False\n",
    "           return ret\n",
    "      else:\n",
    "         ret = False\n",
    "         return ret\n",
    "      \n",
    "  # adjust the number of no spatter below 51\n",
    "  def make(self,filename,filename_test,div,sec):\n",
    "    #フォルダに存在するファイルを取得する、0001.jpg~0005.jpg→{}/*.jpg\n",
    "    \n",
    "    if self.speed==100:\n",
    "       spatter = [self.spatter_data_13,self.spatter_data_14,self.spatter_data_15,\n",
    "                  self.spatter_data_16,[],self.spatter_data_18,self.spatter_data_19,\n",
    "                  [self.spatter_data_20],self.spatter_data_21,[self.spatter_data_22],\n",
    "                  self.spatter_data_23,self.spatter_data_24,self.spatter_data_25,\n",
    "                  self.spatter_data_26,self.spatter_data_27,[self.spatter_data_28],\n",
    "                  self.spatter_data_29,self.spatter_data_30,self.spatter_data_31,\n",
    "                  self.spatter_data_32,self.spatter_data_33,self.spatter_data_34,\n",
    "                  self.spatter_data_35,[self.spatter_data_36],self.spatter_data_37,\n",
    "                  self.spatter_data_38,self.spatter_data_39,[self.spatter_data_40],\n",
    "                  [self.spatter_data_41],self.spatter_data_42\n",
    "                  ]\n",
    "    elif self.speed == 200:\n",
    "      spatter = [[self.spatter_data_51],self.spatter_data_52,[self.spatter_data_53],\n",
    "                  self.spatter_data_54,self.spatter_data_55,self.spatter_data_56,\n",
    "                  [self.spatter_data_57],self.spatter_data_58,[self.spatter_data_59],\n",
    "                  self.spatter_data_60,[self.spatter_data_61],self.spatter_data_62,\n",
    "                  self.spatter_data_63,self.spatter_data_64,self.spatter_data_65,\n",
    "                  [self.spatter_data_66],self.spatter_data_67,self.spatter_data_68,\n",
    "                  [self.spatter_data_69],self.spatter_data_70,self.spatter_data_71,\n",
    "                  self.spatter_data_72,[self.spatter_data_73],[self.spatter_data_74],\n",
    "                  self.spatter_data_75,self.spatter_data_76,[self.spatter_data_77],\n",
    "                  [self.spatter_data_78],self.spatter_data_79,[self.spatter_data_80]\n",
    "                  ]\n",
    "    \n",
    "    #set src img directory\n",
    "    src_img_dir = os.path.join(self.src_dir,\"{}\\crop\".format(div))\n",
    "    #make save directory\n",
    "    save_dir= os.path.join(self.src_dir,\"{}\\{}\".format(div,self.dir_concatImg))\n",
    "    if not os.path.exists(save_dir):\n",
    "      os.mkdir(save_dir)\n",
    "\n",
    "    #spatter count\n",
    "    count_spatter = 0\n",
    "    count_nonspatter = 0\n",
    "    #get num of file in a directory\n",
    "    num_photo = sum(os.path.isfile(os.path.join(src_img_dir,name)) for name in os.listdir(src_img_dir))\n",
    "    print(\"{}-{} progressing :: {}\".format(div,sec,num_photo))\n",
    "    #make dataset\n",
    "    for i in range(10,num_photo-10):\n",
    "      file_path = os.path.join(src_img_dir,f\"{i:03d}.jpg\")\n",
    "      ret = self.checkImg(file_path=file_path)\n",
    "      #laser welding has started\n",
    "      if ret :\n",
    "        #spater frame\n",
    "        if (((i+10) in spatter[div-self.start_index]) or ((i+9) in spatter[div-self.start_index]) or ((i+8) in spatter[div-self.start_index]) or \n",
    "            ((i+7) in spatter[div-self.start_index]) or ((i+6) in spatter[div-self.start_index]) or ((i+5) in spatter[div-self.start_index]) or \n",
    "            ((i+4) in spatter[div-self.start_index]) or ((i+3) in spatter[div-self.start_index]) or ((i+2) in spatter[div-self.start_index])):  \n",
    "          #whether spatter frame is included in input frame\n",
    "          if ((i not in spatter[div-self.start_index]) and ((i-1) not in spatter[div-self.start_index]) and ((i-2) not in spatter[div-self.start_index]) and \n",
    "              ((i-3) not in spatter[div-self.start_index]) and ((i-4) not in spatter[div-self.start_index]) and ((i-5) not in spatter[div-self.start_index]) and \n",
    "            ((i-6) not in spatter[div-self.start_index]) and ((i-7) not in spatter[div-self.start_index]) and ((i-8) not in spatter[div-self.start_index]) and\n",
    "            ((i-9) not in spatter[div-self.start_index])):\n",
    "            #concatenate images\n",
    "            file_path = self.concatImg(index=i,src_img_dir=src_img_dir,save_dir=save_dir,INVERSE = False)\n",
    "            if random.random() >= 0.1: #90% is train data\n",
    "              with open(filename,\"a\",newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([1,file_path])\n",
    "            else:\n",
    "              with open(filename_test,\"a\",newline='') as f:\n",
    "                  writer = csv.writer(f)\n",
    "                  writer.writerow([1,file_path])\n",
    "            count_spatter += 1\n",
    "        #non-spatter frame\n",
    "        else:\n",
    "          #whether spatter frame is included in input frame\n",
    "          if ((i not in spatter[div-self.start_index]) and ((i-1) not in spatter[div-self.start_index]) and ((i-2) not in spatter[div-self.start_index]) and \n",
    "              ((i-3) not in spatter[div-self.start_index]) and ((i-4) not in spatter[div-self.start_index]) and ((i-5) not in spatter[div-self.start_index]) and \n",
    "              ((i-6) not in spatter[div-self.start_index]) and ((i-7) not in spatter[div-self.start_index]) and ((i-8) not in spatter[div-self.start_index]) and \n",
    "              ((i-9) not in spatter[div-self.start_index])) :\n",
    "            #random function for variety of dataset\n",
    "            if self.speed==100:\n",
    "              threshold_nonSpatter=0.985\n",
    "            elif self.speed==200:\n",
    "              threshold_nonSpatter=0.97\n",
    "            if random.random() >= threshold_nonSpatter:\n",
    "              #concatenate images\n",
    "              file_path = self.concatImg(index=i,src_img_dir=src_img_dir,save_dir=save_dir,INVERSE = False)\n",
    "              if random.random() >= 0.1: #90% is train data\n",
    "                with open(filename,\"a\",newline='') as f:\n",
    "                  writer = csv.writer(f)\n",
    "                  writer.writerow([0,file_path])\n",
    "              else:\n",
    "                with open(filename_test,\"a\",newline='') as f:\n",
    "                  writer = csv.writer(f)\n",
    "                  writer.writerow([0,file_path])\n",
    "              count_nonspatter += 1\n",
    "    print(f\"Finished! Spatter :: {count_spatter}, Non-spatter :: {count_nonspatter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Initialize csv dataset?\n",
    "INITIALIZE = True\n",
    "\n",
    "\n",
    "\n",
    "#prepare csv files\n",
    "file_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\csv\\ViT'\n",
    "filename=os.path.join(file_dir,\"train_vit_IR1000_B500_S100.csv\")\n",
    "filename_test=os.path.join(file_dir,\"test_vit_IR1000_B500_S100.csv\")\n",
    "#///////////////////\n",
    "if INITIALIZE:\n",
    "  #make csv file\n",
    "  with open(filename,\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Spatter\",\"Path\"])\n",
    "\n",
    "  with open(filename_test,\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Spatter\",\"Path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## speed=100 mm/sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:33: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\13_spatter.txt\"\n",
      "  self.spatter_data_13 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(13)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:35: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\15_spatter.txt\"\n",
      "  self.spatter_data_15 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(15)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:36: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\16_spatter.txt\"\n",
      "  self.spatter_data_16 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(16)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:38: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\18_spatter.txt\"\n",
      "  self.spatter_data_18 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(18)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:39: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\19_spatter.txt\"\n",
      "  self.spatter_data_19 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(19)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:41: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\21_spatter.txt\"\n",
      "  self.spatter_data_21 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(21)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:43: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\23_spatter.txt\"\n",
      "  self.spatter_data_23 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(23)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:45: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\25_spatter.txt\"\n",
      "  self.spatter_data_25 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(25)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:46: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\26_spatter.txt\"\n",
      "  self.spatter_data_26 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(26)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:50: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\30_spatter.txt\"\n",
      "  self.spatter_data_30 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(30)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:52: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\32_spatter.txt\"\n",
      "  self.spatter_data_32 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(32)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:54: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\34_spatter.txt\"\n",
      "  self.spatter_data_34 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(34)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:57: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\37_spatter.txt\"\n",
      "  self.spatter_data_37 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(37)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:59: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 100mm_s\\video\\39_spatter.txt\"\n",
      "  self.spatter_data_39 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(39)), dtype='int').tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 3\n",
      "14-1 progressing :: 498\n",
      "Finished! Spatter :: 15, Non-spatter :: 7\n",
      "15-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 3\n",
      "16-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 13\n",
      "17-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 3\n",
      "18-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 10\n",
      "19-1 progressing :: 497\n",
      "Finished! Spatter :: 0, Non-spatter :: 4\n",
      "20-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 9\n",
      "21-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 8\n",
      "22-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 10\n",
      "23-1 progressing :: 497\n",
      "Finished! Spatter :: 0, Non-spatter :: 8\n",
      "24-1 progressing :: 497\n",
      "Finished! Spatter :: 8, Non-spatter :: 3\n",
      "25-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 3\n",
      "26-1 progressing :: 495\n",
      "Finished! Spatter :: 0, Non-spatter :: 7\n",
      "27-1 progressing :: 495\n",
      "Finished! Spatter :: 16, Non-spatter :: 5\n",
      "28-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 5\n",
      "29-1 progressing :: 495\n",
      "Finished! Spatter :: 6, Non-spatter :: 0\n",
      "30-1 progressing :: 497\n",
      "Finished! Spatter :: 0, Non-spatter :: 4\n",
      "31-1 progressing :: 497\n",
      "Finished! Spatter :: 26, Non-spatter :: 4\n",
      "32-1 progressing :: 497\n",
      "Finished! Spatter :: 0, Non-spatter :: 0\n",
      "33-1 progressing :: 498\n",
      "Finished! Spatter :: 9, Non-spatter :: 2\n",
      "34-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 4\n",
      "35-1 progressing :: 499\n",
      "Finished! Spatter :: 15, Non-spatter :: 1\n",
      "36-1 progressing :: 497\n",
      "Finished! Spatter :: 6, Non-spatter :: 7\n",
      "37-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 5\n",
      "38-1 progressing :: 492\n",
      "Finished! Spatter :: 7, Non-spatter :: 1\n",
      "39-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 3\n",
      "40-1 progressing :: 497\n",
      "Finished! Spatter :: 8, Non-spatter :: 2\n",
      "41-1 progressing :: 498\n",
      "Finished! Spatter :: 7, Non-spatter :: 2\n",
      "42-1 progressing :: 497\n",
      "Finished! Spatter :: 11, Non-spatter :: 3\n"
     ]
    }
   ],
   "source": [
    "START = 13\n",
    "dataset = Dataset(start_index=START,x_patch = 3, y_patch = 3, height = 80,width = 80,speed=100,\n",
    "                date = \"20230823\",\n",
    "                src_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20230823\\IR1000_B500_S100',\n",
    "                dir_concatImg = \"concat_vit\"\n",
    "                )\n",
    "\n",
    "#make dataset one by one\n",
    "for i in range(13,43):\n",
    "  for j in range(1,2):\n",
    "    dataset.make(filename=filename,filename_test=filename_test,div = i,sec = j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 2)\n",
      "(21, 2)\n",
      "train data\n",
      "Spatter/toal : 123/252\n",
      "test data\n",
      "Spatter/toal : 11/21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_train = pd.read_csv(filename)\n",
    "train = file_train.values\n",
    "labels_train = train[:,0]\n",
    "print(train.shape)\n",
    "file_test = pd.read_csv(filename_test)\n",
    "test = file_test.values\n",
    "labels_test = test[:,0]\n",
    "print(test.shape)\n",
    "def count_spatter(labels):\n",
    "    count = 0\n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == 1:\n",
    "            count += 1\n",
    "    print(f\"Spatter/toal : {count}/{labels.shape[0]}\")\n",
    "\n",
    "print(\"train data\")\n",
    "count_spatter(labels_train)\n",
    "print(\"test data\")\n",
    "count_spatter(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## speed=200 m/sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Initialize csv dataset?\n",
    "INITIALIZE = True\n",
    "\n",
    "\n",
    "\n",
    "#prepare csv files\n",
    "file_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\csv\\ViT'\n",
    "filename=os.path.join(file_dir,\"train_vit_IR1000_B500_S200.csv\")\n",
    "filename_test=os.path.join(file_dir,\"test_vit_IR1000_B500_S200.csv\")\n",
    "#///////////////////\n",
    "if INITIALIZE:\n",
    "  #make csv file\n",
    "  with open(filename,\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Spatter\",\"Path\"])\n",
    "\n",
    "  with open(filename_test,\"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Spatter\",\"Path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:68: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\54_spatter.txt\"\n",
      "  self.spatter_data_54 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(54)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:69: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\55_spatter.txt\"\n",
      "  self.spatter_data_55 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(55)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:72: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\58_spatter.txt\"\n",
      "  self.spatter_data_58 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(58)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:74: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\60_spatter.txt\"\n",
      "  self.spatter_data_60 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(60)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:76: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\62_spatter.txt\"\n",
      "  self.spatter_data_62 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(62)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:78: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\64_spatter.txt\"\n",
      "  self.spatter_data_64 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(64)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:79: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\65_spatter.txt\"\n",
      "  self.spatter_data_65 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(65)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:81: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\67_spatter.txt\"\n",
      "  self.spatter_data_67 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(67)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:82: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\68_spatter.txt\"\n",
      "  self.spatter_data_68 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(68)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:84: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\70_spatter.txt\"\n",
      "  self.spatter_data_70 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(70)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:85: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\71_spatter.txt\"\n",
      "  self.spatter_data_71 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(71)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:86: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\72_spatter.txt\"\n",
      "  self.spatter_data_72 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(72)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:90: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\76_spatter.txt\"\n",
      "  self.spatter_data_76 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(76)), dtype='int').tolist()\n",
      "C:\\Users\\Furukawa\\AppData\\Local\\Temp\\ipykernel_33008\\3221173562.py:93: UserWarning: loadtxt: input contained no data: \"C:\\Users\\Furukawa\\Documents\\TechAssistant\\Video\\20230823_synchronized\\IR_1000W, B_500W, 200mm_s\\video\\79_spatter.txt\"\n",
      "  self.spatter_data_79 = np.loadtxt(os.path.join(dir,'{}_spatter.txt'.format(79)), dtype='int').tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51-1 progressing :: 499\n",
      "Finished! Spatter :: 4, Non-spatter :: 4\n",
      "52-1 progressing :: 497\n",
      "Finished! Spatter :: 6, Non-spatter :: 3\n",
      "53-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 2\n",
      "54-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 7\n",
      "55-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 3\n",
      "56-1 progressing :: 498\n",
      "Finished! Spatter :: 12, Non-spatter :: 0\n",
      "57-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 2\n",
      "58-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 4\n",
      "59-1 progressing :: 499\n",
      "Finished! Spatter :: 8, Non-spatter :: 2\n",
      "60-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 3\n",
      "61-1 progressing :: 498\n",
      "Finished! Spatter :: 1, Non-spatter :: 4\n",
      "62-1 progressing :: 496\n",
      "Finished! Spatter :: 0, Non-spatter :: 3\n",
      "63-1 progressing :: 496\n",
      "Finished! Spatter :: 29, Non-spatter :: 0\n",
      "64-1 progressing :: 497\n",
      "Finished! Spatter :: 0, Non-spatter :: 4\n",
      "65-1 progressing :: 497\n",
      "Finished! Spatter :: 0, Non-spatter :: 5\n",
      "66-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 1\n",
      "67-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 2\n",
      "68-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 6\n",
      "69-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 3\n",
      "70-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 4\n",
      "71-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 3\n",
      "72-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 1\n",
      "73-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 4\n",
      "74-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 1\n",
      "75-1 progressing :: 499\n",
      "Finished! Spatter :: 13, Non-spatter :: 6\n",
      "76-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 5\n",
      "77-1 progressing :: 499\n",
      "Finished! Spatter :: 0, Non-spatter :: 3\n",
      "78-1 progressing :: 498\n",
      "Finished! Spatter :: 4, Non-spatter :: 3\n",
      "79-1 progressing :: 498\n",
      "Finished! Spatter :: 0, Non-spatter :: 4\n",
      "80-1 progressing :: 499\n",
      "Finished! Spatter :: 8, Non-spatter :: 2\n"
     ]
    }
   ],
   "source": [
    "START = 51\n",
    "dataset = Dataset(start_index=START,x_patch = 3, y_patch = 3, height = 80,width = 80,speed=200,\n",
    "                date = \"20230823\",\n",
    "                src_dir = r'C:\\Users\\Furukawa\\Documents\\TechAssistant\\dataset\\imgs\\20230823\\IR1000_B500_S200',\n",
    "                dir_concatImg = \"concat_vit\"\n",
    "                )\n",
    "\n",
    "#make dataset one by one\n",
    "for i in range(51,81):\n",
    "  for j in range(1,2):\n",
    "    dataset.make(filename=filename,filename_test=filename_test,div = i,sec = j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 2)\n",
      "(16, 2)\n",
      "train data\n",
      "Spatter/toal : 77/163\n",
      "test data\n",
      "Spatter/toal : 8/16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_train = pd.read_csv(filename)\n",
    "train = file_train.values\n",
    "labels_train = train[:,0]\n",
    "print(train.shape)\n",
    "file_test = pd.read_csv(filename_test)\n",
    "test = file_test.values\n",
    "labels_test = test[:,0]\n",
    "print(test.shape)\n",
    "def count_spatter(labels):\n",
    "    count = 0\n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == 1:\n",
    "            count += 1\n",
    "    print(f\"Spatter/toal : {count}/{labels.shape[0]}\")\n",
    "\n",
    "print(\"train data\")\n",
    "count_spatter(labels_train)\n",
    "print(\"test data\")\n",
    "count_spatter(labels_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "furukawa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
